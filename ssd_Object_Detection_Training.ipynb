{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssd_Object_Detection_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jDtuoij2y5_mvSfEAOghCsKfDE6MPMR9",
      "authorship_tag": "ABX9TyPKKOZUcSaEoYvduN7bzK7A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungshin52/a-PyTorch-Tutorial-to-Object-Detection/blob/master/ssd_Object_Detection_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbxGu-eofOm"
      },
      "source": [
        "**1. Git에서 fork 해오기**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChR4IwAyVvOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1408b6f-425a-4574-a0cb-3a470dab20b9"
      },
      "source": [
        "!git clone https://github.com/sungshin52/a-PyTorch-Tutorial-to-Object-Detection.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Object-Detection'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Total 249 (delta 0), reused 0 (delta 0), pack-reused 249\u001b[K\n",
            "Receiving objects: 100% (249/249), 175.95 MiB | 38.42 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1od4QsYo6Qa"
      },
      "source": [
        "**2. create_data_lists.py 실행하기**\n",
        "\n",
        "create_data_lists.py의 경로를 다음과 같이 수정\n",
        "\n",
        "voc07_path='/content/drive/MyDrive/dataset/VOC2007',\n",
        "                      voc12_path='/content/drive/MyDrive/dataset/VOC2012',\n",
        "                      output_folder='/content/drive/MyDrive/dataset'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFlkoJrSpCrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a5af31-73c9-4c0a-f8fb-233f51fc0529"
      },
      "source": [
        "%cd /content/drive/MyDrive/dataset\n",
        "!python /content/a-PyTorch-Tutorial-to-Object-Detection/create_data_lists.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset\n",
            "\n",
            "There are 16551 training images containing a total of 49653 objects. Files have been saved to /content/drive/MyDrive/dataset.\n",
            "\n",
            "There are 4952 test images containing a total of 14856 objects. Files have been saved to /content/drive/MyDrive/dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgGhPawjfHG"
      },
      "source": [
        "**3. 이미지 데이터 학습**\n",
        "\n",
        "batch size를 16, iterations를 6000, workers를 2, decaying learning rate를 [4000,5000]으로 낮춰 Epoch 수를 11로 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIfMVVyRjnJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da2f46b-c5df-4556-82dc-ae14b2dc1418"
      },
      "source": [
        "!python /content/a-PyTorch-Tutorial-to-Object-Detection/train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset\n",
            "\n",
            "Loaded base model.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Epoch: [0][0/1035]\tBatch Time 20.387 (20.387)\tData Time 5.344 (5.344)\tLoss 23.8458 (23.8458)\t\n",
            "Epoch: [0][200/1035]\tBatch Time 1.067 (2.523)\tData Time 0.000 (1.403)\tLoss 6.9530 (10.2460)\t\n",
            "Epoch: [0][400/1035]\tBatch Time 1.037 (2.520)\tData Time 0.000 (1.435)\tLoss 5.9313 (8.4107)\t\n",
            "Epoch: [0][600/1035]\tBatch Time 1.064 (2.513)\tData Time 0.000 (1.439)\tLoss 5.9415 (7.6243)\t\n",
            "Epoch: [0][800/1035]\tBatch Time 5.679 (2.524)\tData Time 4.639 (1.455)\tLoss 5.9519 (7.1760)\t\n",
            "Epoch: [0][1000/1035]\tBatch Time 1.039 (2.516)\tData Time 0.000 (1.450)\tLoss 5.5143 (6.8767)\t\n",
            "Epoch: [1][0/1035]\tBatch Time 2.525 (2.525)\tData Time 1.484 (1.484)\tLoss 5.5953 (5.5953)\t\n",
            "Epoch: [1][200/1035]\tBatch Time 1.047 (1.095)\tData Time 0.001 (0.009)\tLoss 5.6849 (5.5168)\t\n",
            "Epoch: [1][400/1035]\tBatch Time 1.113 (1.091)\tData Time 0.001 (0.005)\tLoss 5.2592 (5.4444)\t\n",
            "Epoch: [1][600/1035]\tBatch Time 1.067 (1.089)\tData Time 0.001 (0.004)\tLoss 5.3488 (5.3756)\t\n",
            "Epoch: [1][800/1035]\tBatch Time 1.050 (1.089)\tData Time 0.001 (0.003)\tLoss 5.2607 (5.3016)\t\n",
            "Epoch: [1][1000/1035]\tBatch Time 1.098 (1.088)\tData Time 0.001 (0.003)\tLoss 4.6474 (5.2355)\t\n",
            "Epoch: [2][0/1035]\tBatch Time 2.984 (2.984)\tData Time 1.896 (1.896)\tLoss 4.6476 (4.6476)\t\n",
            "Epoch: [2][200/1035]\tBatch Time 1.062 (1.097)\tData Time 0.001 (0.011)\tLoss 4.6838 (4.8536)\t\n",
            "Epoch: [2][400/1035]\tBatch Time 1.085 (1.090)\tData Time 0.001 (0.006)\tLoss 4.7326 (4.7949)\t\n",
            "Epoch: [2][600/1035]\tBatch Time 1.066 (1.087)\tData Time 0.001 (0.004)\tLoss 4.6278 (4.7528)\t\n",
            "Epoch: [2][800/1035]\tBatch Time 1.135 (1.085)\tData Time 0.001 (0.003)\tLoss 4.4781 (4.7106)\t\n",
            "Epoch: [2][1000/1035]\tBatch Time 1.107 (1.084)\tData Time 0.001 (0.003)\tLoss 5.1017 (4.6669)\t\n",
            "Epoch: [3][0/1035]\tBatch Time 2.455 (2.455)\tData Time 1.360 (1.360)\tLoss 4.0820 (4.0820)\t\n",
            "Epoch: [3][200/1035]\tBatch Time 1.109 (1.092)\tData Time 0.001 (0.009)\tLoss 4.3708 (4.3806)\t\n",
            "Epoch: [3][400/1035]\tBatch Time 1.078 (1.086)\tData Time 0.010 (0.005)\tLoss 4.2970 (4.3755)\t\n",
            "Epoch: [3][600/1035]\tBatch Time 1.070 (1.086)\tData Time 0.001 (0.004)\tLoss 4.7002 (4.3523)\t\n",
            "Epoch: [3][800/1035]\tBatch Time 1.053 (1.086)\tData Time 0.000 (0.003)\tLoss 4.4469 (4.3275)\t\n",
            "Epoch: [3][1000/1035]\tBatch Time 1.090 (1.086)\tData Time 0.001 (0.003)\tLoss 4.7701 (4.2983)\t\n",
            "Epoch: [4][0/1035]\tBatch Time 2.818 (2.818)\tData Time 1.649 (1.649)\tLoss 4.2153 (4.2153)\t\n",
            "Epoch: [4][200/1035]\tBatch Time 1.108 (1.172)\tData Time 0.001 (0.083)\tLoss 4.5433 (4.1755)\t\n",
            "Epoch: [4][400/1035]\tBatch Time 1.079 (1.128)\tData Time 0.001 (0.042)\tLoss 3.6323 (4.1405)\t\n",
            "Epoch: [4][600/1035]\tBatch Time 1.081 (1.114)\tData Time 0.001 (0.028)\tLoss 3.8607 (4.1114)\t\n",
            "Epoch: [4][800/1035]\tBatch Time 1.123 (1.107)\tData Time 0.001 (0.022)\tLoss 4.1185 (4.0905)\t\n",
            "Epoch: [4][1000/1035]\tBatch Time 1.098 (1.103)\tData Time 0.001 (0.017)\tLoss 4.1478 (4.0702)\t\n",
            "Epoch: [5][0/1035]\tBatch Time 2.856 (2.856)\tData Time 1.758 (1.758)\tLoss 4.4063 (4.4063)\t\n",
            "Epoch: [5][200/1035]\tBatch Time 1.091 (1.098)\tData Time 0.001 (0.010)\tLoss 3.8561 (3.9009)\t\n",
            "Epoch: [5][400/1035]\tBatch Time 1.096 (1.095)\tData Time 0.001 (0.005)\tLoss 4.0098 (3.8904)\t\n",
            "Epoch: [5][600/1035]\tBatch Time 1.082 (1.093)\tData Time 0.001 (0.004)\tLoss 3.5743 (3.8917)\t\n",
            "Epoch: [5][800/1035]\tBatch Time 1.075 (1.090)\tData Time 0.001 (0.003)\tLoss 4.3746 (3.8814)\t\n",
            "Epoch: [5][1000/1035]\tBatch Time 1.072 (1.089)\tData Time 0.001 (0.003)\tLoss 3.8945 (3.8717)\t\n",
            "Epoch: [6][0/1035]\tBatch Time 2.622 (2.622)\tData Time 1.527 (1.527)\tLoss 4.5479 (4.5479)\t\n",
            "Epoch: [6][200/1035]\tBatch Time 1.058 (1.090)\tData Time 0.001 (0.009)\tLoss 3.6817 (3.8058)\t\n",
            "Epoch: [6][400/1035]\tBatch Time 1.138 (1.087)\tData Time 0.001 (0.005)\tLoss 3.8050 (3.7785)\t\n",
            "Epoch: [6][600/1035]\tBatch Time 1.054 (1.085)\tData Time 0.001 (0.004)\tLoss 3.7249 (3.7655)\t\n",
            "Epoch: [6][800/1035]\tBatch Time 1.054 (1.084)\tData Time 0.001 (0.003)\tLoss 3.7197 (3.7536)\t\n",
            "Epoch: [6][1000/1035]\tBatch Time 1.099 (1.084)\tData Time 0.001 (0.003)\tLoss 4.1949 (3.7419)\t\n",
            "DECAYING learning rate.\n",
            " The new LR is 0.000100\n",
            "\n",
            "Epoch: [7][0/1035]\tBatch Time 3.211 (3.211)\tData Time 2.033 (2.033)\tLoss 4.0583 (4.0583)\t\n",
            "Epoch: [7][200/1035]\tBatch Time 1.078 (1.097)\tData Time 0.001 (0.011)\tLoss 3.4405 (3.5126)\t\n",
            "Epoch: [7][400/1035]\tBatch Time 1.122 (1.091)\tData Time 0.001 (0.006)\tLoss 3.2899 (3.4821)\t\n",
            "Epoch: [7][600/1035]\tBatch Time 1.132 (1.090)\tData Time 0.001 (0.005)\tLoss 3.3577 (3.4644)\t\n",
            "Epoch: [7][800/1035]\tBatch Time 1.065 (1.089)\tData Time 0.001 (0.004)\tLoss 3.8826 (3.4489)\t\n",
            "Epoch: [7][1000/1035]\tBatch Time 1.057 (1.089)\tData Time 0.001 (0.003)\tLoss 3.1723 (3.4424)\t\n",
            "Epoch: [8][0/1035]\tBatch Time 2.315 (2.315)\tData Time 1.217 (1.217)\tLoss 3.3896 (3.3896)\t\n",
            "Epoch: [8][200/1035]\tBatch Time 1.052 (1.093)\tData Time 0.001 (0.007)\tLoss 3.8726 (3.4460)\t\n",
            "Epoch: [8][400/1035]\tBatch Time 1.126 (1.089)\tData Time 0.007 (0.004)\tLoss 3.3091 (3.4289)\t\n",
            "Epoch: [8][600/1035]\tBatch Time 1.058 (1.089)\tData Time 0.001 (0.003)\tLoss 3.2968 (3.4177)\t\n",
            "Epoch: [8][800/1035]\tBatch Time 1.111 (1.089)\tData Time 0.001 (0.002)\tLoss 3.9599 (3.4102)\t\n",
            "Epoch: [8][1000/1035]\tBatch Time 1.131 (1.090)\tData Time 0.007 (0.002)\tLoss 3.6727 (3.4062)\t\n",
            "DECAYING learning rate.\n",
            " The new LR is 0.000010\n",
            "\n",
            "Epoch: [9][0/1035]\tBatch Time 3.084 (3.084)\tData Time 1.912 (1.912)\tLoss 3.9100 (3.9100)\t\n",
            "Epoch: [9][200/1035]\tBatch Time 1.120 (1.097)\tData Time 0.001 (0.010)\tLoss 3.3698 (3.3552)\t\n",
            "Epoch: [9][400/1035]\tBatch Time 1.051 (1.090)\tData Time 0.001 (0.006)\tLoss 3.5362 (3.3698)\t\n",
            "Epoch: [9][600/1035]\tBatch Time 1.124 (1.088)\tData Time 0.001 (0.004)\tLoss 2.9558 (3.3696)\t\n",
            "Epoch: [9][800/1035]\tBatch Time 1.105 (1.088)\tData Time 0.001 (0.003)\tLoss 3.5478 (3.3695)\t\n",
            "Epoch: [9][1000/1035]\tBatch Time 1.050 (1.087)\tData Time 0.001 (0.003)\tLoss 3.6273 (3.3714)\t\n",
            "Epoch: [10][0/1035]\tBatch Time 2.406 (2.406)\tData Time 1.329 (1.329)\tLoss 3.4860 (3.4860)\t\n",
            "Epoch: [10][200/1035]\tBatch Time 1.098 (1.093)\tData Time 0.001 (0.008)\tLoss 2.8333 (3.3805)\t\n",
            "Epoch: [10][400/1035]\tBatch Time 1.105 (1.088)\tData Time 0.001 (0.005)\tLoss 3.5390 (3.3682)\t\n",
            "Epoch: [10][600/1035]\tBatch Time 1.050 (1.086)\tData Time 0.001 (0.003)\tLoss 2.7174 (3.3554)\t\n",
            "Epoch: [10][800/1035]\tBatch Time 1.087 (1.085)\tData Time 0.001 (0.003)\tLoss 3.7790 (3.3564)\t\n",
            "Epoch: [10][1000/1035]\tBatch Time 1.086 (1.085)\tData Time 0.001 (0.003)\tLoss 3.6144 (3.3645)\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CiFE2s6pQq1"
      },
      "source": [
        "**4. model.py의 484~506번째 줄 에러를 다음과 같이 고치기**\n",
        "\n",
        "                suppress = torch.zeros((n_above_min_score)).bool().to(device)  # (n_qualified)\n",
        "\n",
        "                # Consider each box in order of decreasing scores\n",
        "                for box in range(class_decoded_locs.size(0)):\n",
        "                    # If this box is already marked for suppression\n",
        "                    if suppress[box] == 1:\n",
        "                        continue\n",
        "\n",
        "                    # Suppress boxes whose overlaps (with this box) are greater than maximum overlap\n",
        "                    # Find such boxes and update suppress indices\n",
        "                    suppress = suppress | (overlap[box] > max_overlap)\n",
        "                    # The max operation retains previously suppressed boxes, like an 'OR' operation\n",
        "\n",
        "                    # Don't suppress this box, even though it has an overlap of 1 with itself\n",
        "                    suppress[box] = 0\n",
        "\n",
        "                # Store only unsuppressed boxes for this class\n",
        "                image_boxes.append(class_decoded_locs[~suppress])\n",
        "                image_labels.append(\n",
        "                    torch.LongTensor(\n",
        "                        (~suppress).sum().item() * [c]).to(device)\n",
        "                )\n",
        "                image_scores.append(class_scores[~suppress])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtLPGTScpeVw"
      },
      "source": [
        "**5. detect.py의 67번째 줄 font 에러를 다음과 같이 고치기**\n",
        "\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "**99번째 줄 img_path에 들어가는 이미지 경로를 detection 원하는 이미지 경로로 바꾼 후 실행**\n",
        "\n",
        "**102번째 줄을 다음과 같이 고쳐 detection 수행한 이미지 저장 (min_score 올려 민감도를 낮춤)**\n",
        "\n",
        "detect(original_image, min_score=0.4, max_overlap=0.5, top_k=200).save(\"./out.jpg\")\n",
        "\n",
        "**Video detection의 경우 ssd_detection_video.py 참고**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fftHjE-trTuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188b5808-2ace-4c60-d88d-a5dfe14a1317"
      },
      "source": [
        "%cd /content/drive/MyDrive/dataset\n",
        "!python /content/a-PyTorch-Tutorial-to-Object-Detection/detect.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset\n",
            "\n",
            "Loaded checkpoint from epoch 11.\n",
            "\n",
            "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
            "총 Frame 갯수: 259\n",
            "더 이상 처리할 frame이 없습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}